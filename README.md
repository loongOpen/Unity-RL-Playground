# â€œæ ¼ç‰©â€å…·èº«æ™ºèƒ½ä»¿çœŸå¹³å°
**æ ¼ç‰©å¹³å°å›¾æ–‡ç‰ˆå®‰è£…ä½¿ç”¨æ•™ç¨‹ï¼š**
https://gvtdwawnc78.feishu.cn/wiki/BdQywjXQ0iHPrGkICsUct4Nenqg?from=from_copylink
- **2025.5.25ï¼Œæ·»åŠ å¤æ‚åœ°å½¢ä¾‹ç¨‹**
- **2025.4.19ï¼Œæ·»åŠ åŠ¨ä½œé‡æ˜ å°„ä¾‹ç¨‹ã€æ·»åŠ å››è½®è¶³ä¾‹ç¨‹**
- **2025.4.4ï¼Œæ ¼ç‰©1.0ä¸Šçº¿ï¼Œå…¨é¢å‡çº§**
  æœºå™¨äººè¿åŠ¨ä¼šã€Tinkerè¶³çƒèµ›ã€é’é¾™åŠŸå¤«è¶³çƒå…¨ä¸Šçº¿
  å‡çº§è‡³Unity2023ï¼Œä¾èµ–åŒ…é¢„ç½®ï¼Œä¸‹è½½å³ç”¨ï¼Œä»£ç ä¼˜åŒ–ï¼Œå¼€å‘æ›´æ–¹ä¾¿
- **2025.3.20ï¼Œæ ¼ç‰©0.1ä»£ç å‘å¸ƒ**
  é‡‡ç”¨Unity2021ï¼Œæ‰“åŒ…ä¸ºUnityPackage


<div align="center">
  <h1 align="center">Unitree RL GYM</h1>
  <p align="center">
    <span> ğŸŒEnglish </span> | <a href="README_zh.md"> ğŸ‡¨ğŸ‡³ä¸­æ–‡ </a>
  </p>
</div>

<p align="center">
  <strong>This is a repository for reinforcement learning implementation based on Unitree robots, supporting Unitree Go2, H1, H1_2, and G1.</strong> 
</p>

<div align="center">

| <div align="center"> Isaac Gym </div> | <div align="center">  Mujoco </div> |  <div align="center"> Physical </div> |
|--- | --- | --- |
| [<img src="https://oss-global-cdn.unitree.com/static/32f06dc9dfe4452dac300dda45e86b34.GIF" width="240px">](https://oss-global-cdn.unitree.com/static/5bbc5ab1d551407080ca9d58d7bec1c8.mp4) | [<img src="https://oss-global-cdn.unitree.com/static/244cd5c4f823495fbfb67ef08f56aa33.GIF" width="240px">](https://oss-global-cdn.unitree.com/static/5aa48535ffd641e2932c0ba45c8e7854.mp4) | [<img src="https://oss-global-cdn.unitree.com/static/78c61459d3ab41448cfdb31f6a537e8b.GIF" width="240px">](https://oss-global-cdn.unitree.com/static/0818dcf7a6874b92997354d628adcacd.mp4) |

</div>

---

  
**ç‚¹å‡»è§‚çœ‹è§†é¢‘ï¼ˆ[æœºå™¨äººè¿åŠ¨ä¼š](https://www.bilibili.com/video/BV167RbYxEuG/)ï¼‰**

[![è§†é¢‘å°é¢å›¾ç‰‡](gewu/logo.jpg)](https://www.bilibili.com/video/BV167RbYxEuG/)

**ç‚¹å‡»è§‚çœ‹è§†é¢‘ï¼ˆ[Tinkerè¶³çƒèµ›](https://www.bilibili.com/video/BV1MBo8YUESp/)ï¼‰**

[![è§†é¢‘å°é¢å›¾ç‰‡](soccer.png)](https://www.bilibili.com/video/BV1MBo8YUESp/)

**ç‚¹å‡»è§‚çœ‹è§†é¢‘ï¼ˆ[é’é¾™åŠŸå¤«è¶³çƒ](https://www.bilibili.com/video/BV1NuZBYeEq8/)ï¼‰**

[![è§†é¢‘å°é¢å›¾ç‰‡](kungfusoccer.png)](https://www.bilibili.com/video/BV1NuZBYeEq8/)

â€œæ ¼ç‰©â€æ˜¯ç”±å›½å®¶åœ°æ–¹å…±å»ºäººå½¢æœºå™¨äººåˆ›æ–°ä¸­å¿ƒã€ä¸Šæµ·å¤§å­¦ã€æ¸…åå¤§å­¦è”åˆæ¨å‡ºçš„å…·èº«æ™ºèƒ½ä»¿çœŸè®­ç»ƒå¹³å°ã€‚è¯¥é¡¹ç›®åŸºäºUnity ML-Agentså·¥å…·åŒ…æ„å»ºï¼Œæ—¨åœ¨ä¸ºç ”ç©¶äººå‘˜å’Œå¼€å‘è€…æä¾›ä¸€ä¸ªé«˜æ•ˆä¸”ç”¨æˆ·å‹å¥½çš„å¼ºåŒ–å­¦ä¹ å¼€å‘ç¯å¢ƒï¼Œé€‚ç”¨äºå„ç±»æœºå™¨äººã€‚

## ç›¸å…³è®ºæ–‡

**æ›´å¤šæŠ€æœ¯ç»†èŠ‚ï¼Œæˆ–ä½¿ç”¨æœ¬å¹³å°è¿›è¡Œç ”ç©¶è¯·å‚è€ƒå’Œå¼•ç”¨ä»¥ä¸‹è®ºæ–‡ï¼š**

[1] Ye, Linqi, Rankun Li, Xiaowen Hu, Jiayi Li, Boyang Xing, Yan Peng, and Bin Liang. "Unity RL Playground: A Versatile Reinforcement Learning Framework for Mobile Robots." arXiv preprint arXiv:2503.05146 (2025). [PDF](https://arxiv.org/abs/2503.05146)

[2] Ye, Linqi, Jiayi Li, Yi Cheng, Xianhao Wang, Bin Liang, and Yan Peng. "From knowing to doing: learning diverse motor skills through instruction learning." arXiv preprint arXiv:2309.09167 (2023).[PDF](https://arxiv.org/abs/2309.09167) 

## å¹³å°ç‰¹æ€§
- **å¹¿æ³›çš„æœºå™¨äººæ”¯æŒ**ï¼šå…¼å®¹æ•°ç™¾ç§ç§»åŠ¨æœºå™¨äººï¼ŒåŒ…æ‹¬äººå½¢æœºå™¨äººã€å››è¶³æœºå™¨äººã€è½®å¼æœºå™¨äººç­‰ã€‚
  
- **ä¸€é”®å¯¼å…¥ä¸è®­ç»ƒ**ï¼šå…è®¸ç”¨æˆ·è½»æ¾å¯¼å…¥æœºå™¨äººæ¨¡å‹å¹¶å¯åŠ¨è®­ç»ƒï¼Œæ— éœ€å¤æ‚çš„é…ç½®ã€‚
  
- **é™ä½å¼ºåŒ–å­¦ä¹ å¼€å‘é—¨æ§›**ï¼šç®€åŒ–å·¥ä½œæµç¨‹å¹¶æä¾›å·¥å…·åŒ…ï¼Œä½¿å¼ºåŒ–å­¦ä¹ æŠ€æœ¯äººäººçš†å¯æ¥è§¦å’Œä½¿ç”¨ã€‚
  
## å¼€æºä¸ç¤¾åŒºæ”¯æŒ
- **å¼€æºé¡¹ç›®**ï¼šUnity RL Playgroundæ˜¯å®Œå…¨å¼€æºçš„ï¼Œä»£ç å’Œèµ„æºåœ¨GitHubä¸Šå…¬å¼€å¯ç”¨ï¼Œä¾›å¼€å‘è€…è‡ªç”±è®¿é—®å’Œè´¡çŒ®ã€‚
  
- **ç¤¾åŒºé©±åŠ¨å‘å±•**ï¼šæˆ‘ä»¬æ¬¢è¿å…¨çƒå¼€å‘è€…åŠ å…¥æˆ‘ä»¬çš„ç¤¾åŒºï¼Œå…±åŒæ¨åŠ¨å¹³å°çš„å‘å±•ï¼Œå¹¶åˆ†äº«æŠ€æœ¯ä¸“é•¿ã€‚

â€œæ ¼ç‰©â€è‡´åŠ›äºæˆä¸ºå…·èº«æ™ºèƒ½çš„å¼€æ”¾å¹³å°ï¼ŒåŠ é€Ÿæœºå™¨äººæŠ€æœ¯çš„åˆ›æ–°ã€‚æ— è®ºæ‚¨æ˜¯å­¦æœ¯ç ”ç©¶äººå‘˜ã€å¼€å‘è€…è¿˜æ˜¯çˆ±å¥½è€…ï¼Œéƒ½èƒ½åœ¨è¿™é‡Œæ‰¾åˆ°é‡èº«å®šåˆ¶çš„å·¥å…·å’Œèµ„æºï¼ŒåŠ©åŠ›æ‚¨çš„å·¥ä½œã€‚

**â€œæ ¼ç‰©â€å¹³å°é€‚ç”¨äºWindowsã€Linuxã€macOSç­‰æ“ä½œç³»ç»Ÿ**

## ä¸€ã€ä»¿çœŸç¯å¢ƒå®‰è£…

1. æœç´¢å®‰è£…Unity Hubï¼Œæ³¨å†Œç™»å½•ï¼Œå¼¹å‡ºçš„Install Unity Editorçª—å£ç‚¹å‡»skipè·³è¿‡ï¼Œç„¶åç‚¹å‡»Agree and get personal edition licenseå…è´¹æ¿€æ´»

2. åœ¨æ‰“å¼€çš„Unity Hubç•Œé¢ï¼Œåœ¨Installsèœå•ç‚¹å‡»Install Editorï¼Œé€‰æ‹©Unity Editor 2023ç‰ˆæœ¬ï¼ˆ2023.2.20f1c1ï¼‰å®‰è£…ï¼ˆ7ä¸ªå¤šGï¼Œè€å¿ƒç­‰å¾…ï¼Œè‹¥ä¹‹å‰å®‰è£…äº†2021ç‰ˆæœ¬å¯å°†å…¶å¸è½½ä»¥è…¾å‡ºç©ºé—´ï¼‰

3. ä¸‹è½½Unity RL Playgroundï¼šhttps://github.com/loongOpen/Unity-RL-Playground ï¼Œè§£å‹åˆ°æœ¬åœ°

4. åœ¨Unity Hubçš„Projectsèœå•ä¸­ç‚¹å‡»Openï¼Œé€‰æ‹©ä¸Šä¸€æ­¥è§£å‹çš„Unity-RL-Playground\gewu\Projectç›®å½•ï¼Œç‚¹å‡»Openï¼Œç­‰å¾…é¡¹ç›®æ‰“å¼€ï¼ˆç¬¬ä¸€æ¬¡æ‰“å¼€è€—æ—¶è¾ƒé•¿ï¼Œè€å¿ƒç­‰å¾…ï¼‰

5. é¡¹ç›®æ‰“å¼€åï¼Œåœ¨Unityä¸‹æ–¹çš„å°çª—å£å¯çœ‹åˆ°Assetsç›®å½•ä¸‹çš„RL-Playgroundï¼Œç‚¹å‡»è¿›å…¥è¯¥ç›®å½•ä¸‹ï¼ŒåŒå‡»Playground.unityæ‰“å¼€ï¼Œç‚¹å‡»unityä¸Šé¢çš„ä¸‰è§’å½¢è¿è¡Œå³å¯çœ‹åˆ°æœºå™¨äººé¢„è®­ç»ƒå¥½çš„è¿åŠ¨æ•ˆæœï¼

6. é€‰ä¸­æŸä¸ªæœºå™¨äººï¼Œåœ¨å³è¾¹inspectorçª—å£å¯åœ¨å¯¹åº”çš„target motionä¸‹æ‹‰æ¡†åˆ‡æ¢è¿åŠ¨æ¨¡å¼ï¼ˆå¦‚æœå¯¹åº”çš„é¢„è®­ç»ƒæ¨¡å‹éç©ºï¼‰ã€‚

7. åŒå‡»TinkerPlay.unityæ‰“å¼€å³ä¸ºTinkerè¶³çƒèµ›ï¼Œé¢„è®¾ä¸ºåŒäººå¯¹æˆ˜æ¨¡å¼ï¼Œä¸€äººé€šè¿‡é”®ç›˜ä¸Šçš„WASDé”®æ§åˆ¶è¡Œèµ°æ–¹å‘ã€å·¦ctrlé”®å¤ä½æœºå™¨äººï¼Œå¦ä¸€äººé€šè¿‡é”®ç›˜ä¸Šçš„ä¸Šä¸‹å·¦å³é”®æ§åˆ¶è¡Œèµ°æ–¹å‘ã€å³ctrlé”®å¤ä½æœºå™¨äººï¼Œç©ºæ ¼é”®å¤ä½è¶³çƒ

8. åŒå‡»LoongPlay.unityæ‰“å¼€å³ä¸ºé’é¾™åŠŸå¤«è¶³çƒï¼Œé¢„è®¾ä¸ºè‡ªåŠ¨å¯¹æˆ˜æ¨¡å¼ï¼Œåªå½“è¶³çƒå¡åœ¨è§’è½æ—¶å¯æŒ‰ç©ºæ ¼é”®å¤ä½

9. åŒå‡»Go2.unityæ‰“å¼€ä¸ºå››è¶³æœºå™¨äººå…¨å‘è¡Œèµ°ä¾‹ç¨‹ï¼Œé€šè¿‡WASDå’Œå·¦å³ç®­å¤´æŒ‰é”®æ§åˆ¶è¡Œèµ°æ–¹å‘ï¼Œç©ºæ ¼é”®å¤ä½

10. å½•åˆ¶è§†é¢‘åœ¨èœå•æ Window->General->Recorder->Recorder Windowï¼Œç‚¹å‡»Add Recorder->Movieï¼Œç‚¹å‡»çº¢è‰²ä¸‰è§’å½¢å³å¯å½•åˆ¶ï¼Œåœ¨ä¸‹æ–¹Pathå¯æ‰¾åˆ°ä¿å­˜è·¯å¾„

## åŠ¨ä½œé‡æ˜ å°„ä¾‹ç¨‹ï¼Œç”¨äºå¤æ‚åŠ¨ä½œçš„æ¨¡ä»¿å­¦ä¹ 

åœ¨Assets/Retargetç›®å½•ä¸‹ï¼ŒH1.unityè¿è¡Œåä¼šä¾æ¬¡æ’­æ”¾feedforwardæ–‡ä»¶å¤¹ä¸‹å­˜å…¥çš„é¢„è®¾åŠ¨ä½œ

å¯å‚è€ƒH2O githubä»£ç ç”Ÿæˆæ–°çš„é‡æ˜ å°„åŠ¨ä½œ

## å¤æ‚åœ°å½¢ä¾‹ç¨‹Terrain.unity

é•¿30cmé«˜15cmå°é˜¶ï¼Œé¢„è®­ç»ƒé’é¾™ã€å®‡æ ‘G1ã€åŠ é€Ÿè¿›åŒ–T1ã€ä¼—æ“SA01

æ³¨æ„è®­ç»ƒæ—¶è¦å•ç‹¬æ¯ä¸ªæœºå™¨äººï¼Œå…¶ä»–æœºå™¨äººéšè—

é‡‡ç”¨è¯¾ç¨‹å­¦ä¹ ï¼Œè®­ç»ƒæ—¶é€æ¸å¢å¤§æ¥¼æ¢¯é«˜åº¦ï¼ˆè°ƒæ•´Stairsçš„Scaleçš„yå€¼ï¼‰

## äºŒã€è®­ç»ƒç¯å¢ƒå®‰è£…

1. å®‰è£…Anacondaï¼šhttps://www.anaconda.com/download

2. åœ¨ç”µè„‘æœç´¢æ¡†æœç´¢anacondaï¼Œç‚¹å‡»æ‰“å¼€anacconda promptå‘½ä»¤è¡Œçª—å£

3. è¿è¡Œ`conda create -n gewu python=3.10.12 -y`

    ï¼ˆæ³¨ï¼šè‹¥å®‰è£…äº†ä¹‹å‰çš„è€ç‰ˆæœ¬ï¼Œå¯é€šè¿‡conda remove -n ml-agentså‘½ä»¤å°†å…¶åˆ é™¤ï¼‰

4. è¿è¡Œ`conda activate gewu`

5. è¿è¡Œ`pip3 install torch~=2.2.1 --index-url https://download.pytorch.org/whl/cu121`

    ï¼ˆç¡®ä¿ç½‘ç»œç•…é€šï¼Œè€—æ—¶è¾ƒé•¿ï¼Œè€å¿ƒç­‰å¾…ï¼Œè‹¥å®‰è£…å¤±è´¥å¯æ¢ä¸ªç½‘ç»œè¯•è¯•ï¼‰

6. è¿è¡Œ`python -m pip install mlagents==1.1.0`

    ï¼ˆè€å¿ƒç­‰å¾…ï¼‰

7. è¿è¡Œ`mlagents-learn --help`æ£€æŸ¥æ˜¯å¦å®‰è£…æˆåŠŸï¼ˆæ— æŠ¥é”™å³å¯ï¼‰

## ä¸‰ã€è®­ç»ƒæœºå™¨äºº

1. åœ¨unityæ‰“å¼€Playground.unityï¼Œé€‰ä¸­ä¸€ä¸ªè¦è®­ç»ƒçš„æœºå™¨äººï¼ˆå»ºè®®å…ˆç”¨Go2æµ‹è¯•ï¼‰ï¼Œåœ¨å³ä¾§inspectorä¸­å‹¾é€‰train

2. é€‰ä¸­å…¶ä»–æœºå™¨äººå°†ä»–ä»¬éƒ½éšè—ï¼ˆåœ¨inspectorçª—å£å°†æœ€ä¸Šé¢ä¸€ä¸ªæ–¹æ¡†çš„å‹¾å–æ¶ˆå³å¯ï¼‰

3. å›åˆ°anacondaç•Œé¢ï¼Œè¿›å…¥Unity-RL-Playgroundä¸»ç›®å½•ï¼ˆä¾‹å¦‚ï¼Œå…ˆè¿è¡Œ`D:` å†è¿è¡Œ `cd D:\Unity-RL-Playground-main\gewu\Project\Assets\RL-Playground` ï¼ˆæ ¹æ®è‡ªå·±çš„å®é™…ç›®å½•è°ƒæ•´ï¼‰ï¼‰

4. è¿è¡Œ`mlagents-learn trainer_config.yaml --run-id=go2trot --force`å¼€å§‹è®­ç»ƒ

    ï¼ˆæ³¨ï¼šidå·åç§°å¯è‡ªå·±ä»»å–ï¼Œ--forceä¸ºä»é›¶è®­ç»ƒï¼Œè‹¥ä½¿ç”¨--resumeåˆ™ä¸ºæ–­ç‚¹ç»§ç»­è®­ç»ƒï¼‰
   
6. å½“çª—å£ä¸­å‡ºç°[INFO] Listening on ...æ—¶å›åˆ°unityç•Œé¢ï¼Œç‚¹å‡»ä¸Šé¢çš„ä¸‰è§’å½¢æŒ‰é’®è¿è¡Œå³å¯å¼€å§‹è®­ç»ƒ

7. è®­ç»ƒæ—¶å¯åœ¨anacondaçª—å£è§‚å¯Ÿè®­ç»ƒè¿›åº¦ï¼Œæ­£å¸¸æ¥è¯´å¥–åŠ±ä¼šé€æ¸å‡é«˜ï¼Œä¸€èˆ¬è®­ç»ƒ2000000ä¸ªstepå³å¯ï¼ŒæŒ‰ctrl+cç»ˆæ­¢è®­ç»ƒ

8. ç»ˆæ­¢è®­ç»ƒååœ¨unityç•Œé¢ä¸‹æ–¹æ‰¾åˆ°åˆšåˆšè®­çš„ç¥ç»ç½‘ç»œï¼Œåœ¨results->go2trotï¼ˆåç§°ä¸run-idä¸€è‡´ï¼‰ç›®å½•ä¸­ï¼Œå¯çœ‹åˆ°ä¸€ä¸ªgewu.onnxçš„æ–‡ä»¶ï¼Œå³ä¸ºè®­ç»ƒå¥½çš„ç¥ç»ç½‘ç»œ

9. ç‚¹å‡»é€‰ä¸­æœºå™¨äººï¼Œåœ¨å³ä¾§inspectorçª—å£å¯çœ‹åˆ°å¾ˆå¤špolicyçš„æ–¹æ¡†ï¼Œå°†è®­ç»ƒå¥½çš„ç¥ç»ç½‘ç»œæ‹–åŠ¨åˆ°å¯¹åº”æ–¹æ¡†ä¸­ï¼ˆå¦‚Q trot policyï¼‰

10. åœ¨å³ä¾§inspectorä¸­å–æ¶ˆå‹¾é€‰trainï¼Œè¿è¡Œunityï¼Œå³å¯çœ‹åˆ°æœºå™¨äººçš„è¿åŠ¨æ•ˆæœ

11. ç±»ä¼¼åœ°ï¼Œå¯å¯¹TinkerTrain.unityå’ŒLoongTrain.unityè¿›è¡Œè®­ç»ƒï¼Œè®­ç»ƒæ‰€å¾—çš„ç¥ç»ç½‘ç»œå¯ç”¨äºTinkerPlay.unityå’ŒLoongPlay.unity

## å››ã€å¯¼å…¥å’Œè®­ç»ƒæ–°çš„æœºå™¨äºº

**ä»¥ä¸‹ä»“åº“é›†é½äº†ä¼—å¤šæœºå™¨äººURDFæ¨¡å‹ï¼šhttps://github.com/linqi-ye/robot-universe**

1. å°†æ–°çš„æœºå™¨äººurdfæ–‡ä»¶å¤¹ï¼ˆåŒ…æ‹¬meshesï¼‰æ”¾å…¥Unity-RL-Playground-main\urdfæ–‡ä»¶å¤¹

2. æœºå™¨äººurdfæ–‡ä»¶å¤¹ä¸€èˆ¬å‘½åä¸ºxx_descriptionï¼Œé‡Œé¢åŒ…å«xx.urdfä»¥åŠmeshesæ–‡ä»¶å¤¹ï¼Œxx.urdfé‡Œé¢çš„è·¯å¾„æ ¼å¼ä¸ºpackage://meshes/xxx.STLï¼Œæœºå™¨äººè…¿éƒ¨ä»¥å¤–çš„å…³èŠ‚æœ€å¥½å·²ç»é”å®šã€‚        ï¼ˆæ³¨ï¼šå¦‚æœè…¿éƒ¨ä»¥å¤–æœ‰å…³èŠ‚æœªé”å®šï¼Œå¯åœ¨å¯¼å…¥åæ‰“å¼€æœºå™¨äººç»“æ„æ ‘ï¼Œé€‰ä¸­å¯¹åº”çš„ArticulationBodyå°†Articulation Joint Typeç”±Revoluteæ”¹ä¸ºFixï¼‰

3. åœ¨unityä¸­æ‰“å¼€é¢„åˆ¶çš„ç©ºåœºæ™¯MyRobot.Unity

4. ä»¥ä¼—æ“æœºå™¨äººä¸ºä¾‹ï¼Œåœ¨urdfæ–‡ä»¶å¤¹ä¸­è¿›å…¥zq_humanoidï¼Œå•å‡»é€‰ä¸­zq_sa01.urdfï¼Œç‚¹å‡»èœå•æ Assets->Import Robot from Selected URDFï¼Œå¼¹å‡ºçª—å£ï¼Œå°†mesh decomposeré€‰æ‹©unityï¼Œç‚¹å‡»import URDF

5. çœ‹åˆ°æœºå™¨äººæ¨¡å‹å¯¼å…¥åï¼Œé€‰ä¸­æœºå™¨äººåœ¨å³ä¾§inspectorè°ƒæ•´é«˜åº¦(yè½´)ä½¿å…¶è„šç€åœ°ï¼Œå¯ç¨é«˜ä¸€ç‚¹ç‚¹

6. é€‰ä¸­å¯¼å…¥çš„æœºå™¨äººï¼Œåœ¨inspectorçª—å£å°†Urdf Robot (script)å’ŒController (script) éƒ½åˆ é™¤

7. æ‹–åŠ¨å¯¼å…¥çš„æœºå™¨äººåˆ°MyRobotçš„å­èŠ‚ç‚¹ä¸­

8. é€‰ä¸­MyRobotï¼Œåœ¨inspectorçª—å£é€‰æ‹©å¯¹åº”çš„RobotTypeï¼ˆä¼—æ“æœºå™¨äººä¿æŒé»˜è®¤Bipedå³å¯ï¼‰å’ŒTarget Motionï¼ˆæ­¤ä¾‹åœ¨Bipedä¸‹é¢ä¿æŒé»˜è®¤çš„Walkå³å¯ï¼‰ï¼Œåœ¨Behaviour Parametersè®¾ç½®observationå’Œactionç»´æ•°ï¼ˆæ­¤ä¾‹ä¿æŒé»˜è®¤å³å¯ï¼‰ï¼Œå¯å‚è€ƒå…¶ä»–æœºå™¨äºº

9. è®­ç»ƒå‰æµ‹è¯•ï¼Œé€‰ä¸­Fixbodyå¤é€‰æ¡†ï¼Œè¿è¡ŒunityæŸ¥çœ‹å‰é¦ˆåŠ¨ä½œæ˜¯å¦æ­£ç¡®ï¼ŒåŒè¶³walkæ­¥æ€ä¸‹æœºå™¨äººåº”ä¸Šä¸‹è¸æ­¥

10. å¦‚å‰é¦ˆä¸åŒ¹é…ï¼Œå¯åœ¨GewuAgentä»£ç ä¸­æœç´¢â€œchange hereâ€,æ‰¾åˆ°å¯¹åº”ä»£ç ä¿®æ”¹é€‚åˆæœ¬æœºå™¨äººçš„å‚æ•°ï¼ˆæœ¬ä¾‹ä¸­åœ¨285è¡Œçš„idxå…­ä¸ªæ•°å…¨åŠ ä¸Šè´Ÿå·å³å¯ï¼‰ï¼Œçœ‹åˆ°æœºå™¨äººæ­£å¸¸ä¸Šä¸‹è¸æ­¥å³å¯

    ï¼ˆæ³¨ï¼šidxä»£è¡¨è¦ç»™å‰é¦ˆçš„å…³èŠ‚ï¼Œå¯¹äºåŒè¶³æ˜¯é«‹ã€è†ã€è¸çš„ä¸‰ä¸ªpitchå…³èŠ‚ï¼Œä¸€èˆ¬æ¥è¯´æ•°å€¼ç”¨é»˜è®¤å³å¯ï¼ˆå°‘æ•°æ„å‹ä¸ä¸€è‡´çš„éœ€ä¿®æ”¹ï¼‰ï¼Œæ­£è´Ÿå·å’Œå…³èŠ‚è½¬å‘æœ‰å…³ï¼Œæ ¹æ®æƒ…å†µä¿®æ”¹ï¼‰

11. é…ç½®å®Œæ¯•ï¼Œå³å¯é€šè¿‡`mlagents-learn â€¦â€¦ `è¯­å¥è¿›è¡Œè®­ç»ƒï¼ˆå‚è€ƒâ€œä¸‰â€ä¸­æ­¥éª¤ï¼‰ï¼Œæœ¬ä¾‹åªéœ€è®­ç»ƒ40ä¸‡stepï¼ˆ2ï½5åˆ†é’Ÿï¼‰å³å¯çœ‹åˆ°æ•ˆæœ

# Unity RL Playground

Unity RL Playground (also named **Gewu**) is an embodied intelligence robotics simulation platform jointly launched by the National and Local Co-Built Humanoid Robotics Innovation Center, Shanghai University, and Tsinghua University. Built on top of the Unity ML-Agents Toolkit, this project aims to provide researchers and developers with an efficient and user-friendly reinforcement learning (RL) development environment for various robots.

## Related Publication
Fâ€Œor more details, please read and cite the following papers when conducting research using this platformâ€Œ:

Ye, Linqi, Rankun Li, Xiaowen Hu, Jiayi Li, Boyang Xing, Yan Peng, and Bin Liang. "Unity RL Playground: A Versatile Reinforcement Learning Framework for Mobile Robots." arXiv preprint arXiv:2503.05146 (2025). [PDF](https://arxiv.org/abs/2503.05146)

Ye, Linqi, Jiayi Li, Yi Cheng, Xianhao Wang, Bin Liang, and Yan Peng. "From knowing to doing: learning diverse motor skills through instruction learning." arXiv preprint arXiv:2309.09167 (2023). [PDF](https://arxiv.org/abs/2309.09167) 

## Platform Featuresâ€Œ

- **Extensive Robot Supportâ€Œ**: Compatible with hundreds of mobile robots, including humanoid robots, quadruped robots, wheeled robots, and more.
- **One-Click Import & Trainingâ€Œ**: Allowing users to effortlessly import robot models and initiate training without complex configurations.
- **Lowered RL Development Barrierâ€Œ**: Simplifies workflows and provides toolkits to make RL technology accessible and approachable for everyone.

## Open-Source & Community Supportâ€Œ

- **Open-Source Projectâ€Œ**: Unity RL Playground is fully open-source, with code and resources publicly available on GitHub for developers to freely access and contribute.
- **Community-Driven Growthâ€Œ**: We welcome global developers to join our community, collaborate on advancing the platform, and share technical expertise.

Unity RL Playground is committed to becoming an open platform for embodied intelligence, accelerating innovation in robotics technology. Whether you are an academic researcher, developer, or enthusiast, you will find tailored tools and resources here to empower your work.

## I. Simulation Environment Installation

1. Search for and install Unity Hub, register and log in. When the "Install Unity Editor" window pops up, click "skip", then click "Agree and get personal edition license" to activate it for free.

2. In the opened Unity Hub interface, click "Install Editor" under the "Installs" menu, and select the Unity Editor 2023 version (2023.2.20f1c1) for installation (over 7GB, please be patient. If the 2021 version was previously installed, it can be uninstalled to free up space).

3. Download Unity RL Playground: [https://github.com/loongOpen/Unity-RL-Playground](https://github.com/loongOpen/Unity-RL-Playground), and unzip it to a local directory.

4. In the "Projects" menu of Unity Hub, click "Open", select the Unity-RL-Playground\gewu\Project directory from the previous step, click "Open", and wait for the project to open (the first time may take longer, please be patient).

5. After the project opens, in the small window at the bottom of Unity, you can see the RL-Playground directory under the Assets directory. Click to enter this directory, double-click Playground.unity to open it, and click the triangle at the top of Unity to run it to see the pre-trained movement effects of the robot!

6. Select a robot, and in the inspector window on the right, you can switch the movement mode in the corresponding target motion dropdown box (if the corresponding pre-trained model is not empty).

7. Double-click TinkerPlay.unity to open the Tinker soccer game, which is preset to a two-player battle mode. One player controls the walking direction with the WASD keys on the keyboard and resets the robot with the left Ctrl key, while the other player controls the walking direction with the arrow keys and resets the robot with the right Ctrl key. Press the spacebar to reset the soccer ball.

8. Double-click LoongPlay.unity to open the Loong Kung Fu Soccer, which is preset to an automatic battle mode. Press the spacebar to reset the soccer ball only when it gets stuck in a corner.

9. Double-click Go2.unity to open the quadrupedal robot omnidirectional walking routine. Control the walking direction with the WASD and arrow keys, and press the spacebar to reset.

10. To record a video, go to the menu bar Window->General->Recorder->Recorder Window, click Add Recorder->Movie, click the red triangle to start recording, and find the save path under Path.

## II. Training Environment Installation

1. Install Anaconda: [https://www.anaconda.com/download](https://www.anaconda.com/download)

2. Search for Anaconda in the computer search box, and click to open the Anaconda Prompt command line window.

3. Run `conda create -n gewu python=3.10.12 -y`

    (Note: If an older version was previously installed, it can be removed with the command `conda remove -n ml-agents`)

4. Run `conda activate gewu`

5. Run `pip3 install torch~=2.2.1 --index-url https://download.pytorch.org/whl/cu121`

    (Ensure a stable network connection, as this may take a while. If the installation fails, try a different network.)

6. Run `python -m pip install mlagents==1.1.0`

    (Be patient.)

7. Run `mlagents-learn --help` to check if the installation was successful (no errors means success).

## III. Training the Robot

1. Open Playground.unity in Unity, select a robot to train (it is recommended to start with Go2 for testing), and check the "train" box in the inspector on the right.

2. Hide the other robots (uncheck the top box in the inspector window).

3. Return to the Anaconda interface and navigate to the main directory of Unity-RL-Playground (for example, first run `D:` and then `cd D:\Unity-RL-Playground-main\gewu\Project\Assets\Unity-RL-Playground-main` (adjust according to your actual directory)).

4. Run `mlagents-learn trainer_config.yaml --run-id=go2trot --force` to start training (Note: the run-id can be named as desired, `--force` starts training from scratch, while `--resume` continues training from a checkpoint).

5. When "[INFO] Listening on ..." appears in the window, return to the Unity interface, click the triangle button at the top to start training.

6. During training, you can observe the training progress in the Anaconda window. Normally, the reward will gradually increase. Generally, train for 2,000,000 steps, and press Ctrl+C to terminate the training.

7. After terminating the training, find the newly trained neural network in the results->go2trot (the name matches the run-id) directory, where you can see a gewu.onnx file, which is the trained neural network.

8. Click to select the robot, and in the inspector window on the right, you can see many policy boxes. Drag the trained neural network into the corresponding box (e.g., Q trot policy).

9. Uncheck the "train" box in the inspector on the right, and run Unity to see the robot's movement effects.

10. Similarly, you can train TinkerTrain.unity and LoongTrain.unity, and the trained neural networks can be used in TinkerPlay.unity and LoongPlay.unity.

## IV. Importing and Training a New Robot

**The following repository collects numerous robot URDF models: [https://github.com/linqi-ye/robot-universe](https://github.com/linqi-ye/robot-universe)**

1. Place the new robot's URDF folder (including meshes) into the Unity-RL-Playground-main\urdf folder.

2. The robot's URDF folder is generally named xx_description, which contains xx.urdf and a meshes folder. The path format in xx.urdf is package://meshes/xxx.STL. It is best if the joints other than the robot's legs are already locked. (Note: If there are unlocked joints other than the legs, you can open the robot's structure tree after importing, select the corresponding ArticulationBody, and change the Articulation Joint Type from Revolute to Fix.)

3. Open the prefabricated empty scene MyRobot.Unity in Unity.

4. Taking the Zhongqing robot as an example, navigate to zq_humanoid in the urdf folder, click to select zq_sa01.urdf, click Assets->Import Robot from Selected URDF in the menu bar, in the pop-up window, select unity for mesh decomposer, and click import URDF.

5. After seeing the imported robot model, select the robot and adjust its height (y-axis) in the inspector on the right to make its feet touch the ground (it can be slightly higher).

6. Select the imported robot, and in the inspector window, delete both the Urdf Robot (script) and Controller (script).

7. Drag the imported robot into the child node of MyRobot.

8. Select MyRobot, and in the inspector window, choose the corresponding RobotType (keep the default Biped for the Zhongqing robot) and Target Motion (in this case, keep the default Walk under Biped), and set the observation and action dimensions in Behaviour Parameters (keep the default in this case, you can refer to other robots).

9. Before training, test by checking the Fixbody checkbox, run Unity to see if the feedforward action is correct. The robot should take up-and-down steps in the bipedal walk gait.

10. If the feedforward does not match, you can search for "change here" in the GewuAgent code, find the corresponding code to modify the parameters suitable for this robot (in this case, add a negative sign to all six numbers on line 285), and ensure the robot takes normal up-and-down steps.

    (Note: idx represents the joints to be fed forward. For bipeds, these are the three pitch joints of the hip, knee, and ankle. Generally, the default values can be used (modify only if the configuration is inconsistent), and the positive/negative signs are related to the joint direction, so adjust according to the situation.)

11. After configuration, you can train using the `mlagents-learn ...` statement (refer to the steps in "III"). In this case, only 400,000 steps (2-5 minutes) are needed to see the effect.
